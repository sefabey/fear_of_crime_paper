---
title: "Lexicon of Crime and Police Words"
author: "Sefa Ozalp"
date: "26/07/2018"
output:
      html_document:
        keep_md: true
        toc: true # table of content true
        toc_depth: 2  # upto three depths of headings (specified by #, ## and ###)
        number_sections: true  ## if you want number sections at each table header
        theme: united
---
```{r}
knitr::opts_chunk$set(warning = F)
```



```{r}
library(tidyverse)
library(rhymer)
# install.packages('rhymer')
```

# The Lexicon Paragraph
We compiled a list of 44 seeding words which includes words used when expressing fear of crime, different crime types and British slangs referring to police and criminal activity (find this list online [https://github.com/sefabey/fear_of_crime_paper/blob/master/data/FOC_seed_words_002.csv]). The seed list was used to create the lexicon by querying the Datamuse API -a word-finding engine which allows for querying rhyming words, similar spellings and semantically similar or contextually related words using multiple contraints such as synonyms, perfect and approximate rhymes, homophones, frequent followers, direct holonyms. Using the rhymer package (Landesberg 2017) in R, we queried Datamuse API for the first 100 words that 'means like' -i.e. words or sequence of words that are conceptually, semantically and lexically related to- the words in the seed list. After removing duplicates and manually removing clearly out of context results (such as query:coppers, Datamuse result:atomic number 29), we gathered a lexicon consisting of 2538 terms. We also identified 139 slang terms that are used by London gangs and inspected the usage of these terms on Twitter. (see this for methodology [http://rpubs.com/sefaozalp/gang_slangs]). We found that only 16 out of 139 gang slang terms were useful to identify tweets referring to crime and criminal activity. After adding these terms, we collated a lexicon consisting of 2554 terms that could be useful to identify tweets referring to crime, disorder or criminal activty on Twitter  (find this file online [https://github.com/sefabey/fear_of_crime_paper/blob/master/data/FOC_lexicon_003_final.csv]). 

This lexicon was used to filter the 20m tweets in the dataset... (amir)

# Steps to Create the Lexicon

## Seed list
```{r}

seed_list <- read_csv("../data/FOC_seed_words.csv")
seed_list %>% distinct(words) #51 distinct words
```

```{r, warning=F}

query_datamuse <- function(x, ...){
    rhymer::get_means_like(word = x, ...)
}

crime_fear_lexicon <- seed_list %>% 
    select(words) %>%
    pull() %>%  
    map_df(query_datamuse, limit=100, .id = "id") %>% #5030 results
    mutate(id=as.integer(id)) %>% 
    distinct(word, .keep_all = T) %>% # drops to 3687
    left_join( select(seed_list, c(id, query_word=words)), by="id") %>% 
    select(id, query_word, everything()) %>% 
    mutate(tags=as.character(tags)) %>% 
    separate(tags, sep = ",", into = c("tag1", "tag2", "tag3", "tag4")) %>% 
    mutate_at(vars(tag1,tag2,tag3,tag4), .funs = function(x){
              str_extract(string=x, pattern =  regex("(?<=\")[[:alnum:]]+(?=\")"))})


# write_csv(crime_fear_lexicon,"../data/FOC_lexicon_001.csv")

# 
```
Not memoising above because no need as wrote to csv file once and using that.


Below removing words to remove identified manually. Again wrote once and commented oit write function.
```{r}
lexicon_filtered <- read_csv("../data/FOC_lexicon_001_manual.csv") %>% 
    filter(remove==0) # rows to be removed was labelled as 1, rest was 0

lexicon_filtered

# write_csv(lexicon_filtered, "../data/FOC_lexicon_001_manual_edited.csv")
```

# Take 2

New comments from the PI, need to do the following.

1) Remove fear related words from the seed list and lexicon
2) Revisit the final version of the lexicon and remove irrelevant words (such as drugs ~ prescription, charlatan)


### 2.1. Removing fear related words from the seed list and then from the lexicon.
```{r}
read_csv("../data/FOC_seed_words.csv") %>% 
    filter(context %in% c("fear")) # print fear related words

seed_list_002 <- read_csv("../data/FOC_seed_words.csv") %>% 
    filter(!context %in% c("fear")) %>% # glad that i added context var previously
    filter(!words=="shank") %>% # not that related
    mutate(id=seq.int(nrow(.)))

# write_csv(seed_list_002, "../data/FOC_seed_words_002.csv")
```

```{r}
lexicon_2 <- read_csv("../data/FOC_lexicon_001_manual_edited.csv") %>% 
    filter(!query_word %in% c("afraid","alone", "avoid", "fear", "scary", "worried")) %>% 
    select(-id) %>% 
    left_join(seed_list_002, by = c("query_word"="words")) %>% 
    select(id, everything(),-context, -explanation) # decrease to 

# write_csv(lexicon_2, "../data/FOC_lexicon_002.csv")
```

## Revisit and remove irrelevant words

This is going to be done manually and outside R. 

Removing manually identified words

```{r}
lexicon_filtered_02 <- read_csv("../data/FOC_lexicon_002_manual.csv") %>% 
    filter(remove==0) # rows to be removed was labelled as 1, rest was 0

lexicon_filtered_02

write_csv(lexicon_filtered_02, "../data/FOC_lexicon_002_manual_edited.csv")
```


As words in English can take many forms, suffixes and prefixes, I'll add lemmas and stems of words in seperate columns. 

```{r}
lexicon_filtered_02 <- lexicon_filtered_02 %>% 
    mutate(lemmas=textstem::lemmatize_strings(word)) %>% 
    mutate(stems= textstem::stem_strings(word)) %>% 
    select(everything(),-remove, remove)

lexicon_filtered_02

write_csv(lexicon_filtered_02, "../data/FOC_lexicon_002_manual_edited.csv")
```

# Final Version of the Lexicon

## Merging with London Slangs

After the lexicon was created, I have moved on to explore the London based gang slangs and whether they would be useful to include in the lexicon for the purposes of this study. The methods used to explore the use of London gang slang terms on Twitter are detailed here [http://rpubs.com/sefaozalp/gang_slangs]. In summary, I have explored the use of 139 London gang slang terms on Twitter and found out that only a fraction of these terms were vaguely referred to crime or criminal activity. Find the results of the exploration here [https://github.com/sefabey/fear_of_crime_paper/blob/master/data/slangs_from_shinobi.csv] and here [https://github.com/sefabey/fear_of_crime_paper/blob/master/data/ereid_glossary.csv].


Below, I will merge the London gang slang terms which were identified to have referred to crime or criminal activity with the lexicon. 


```{r, message=F}
lexicon_filtered_02 <- read_csv("../data/FOC_lexicon_002_manual_edited.csv")
shinobi_glossary <- read_csv("../data/slangs_from_shinobi.csv")
ereid_glossary <- read_csv("../data/ereid_glossary.csv")
```

Slang terms that might be useful and collected from shinobi are:

```{r}
shinobi_useful <- shinobi_glossary %>%
    filter(useful_for_further_inspection!= "no") %>% 
    filter(!is.null(slang_term))

shinobi_useful

```


Slang terms that might be useful and collected from Ebony Reid's PhD thesis are:
```{r}
ereid_useful <- ereid_glossary %>% 
    filter(useful_for_further_inspection!="no") %>% 
    filter(!is.na(slang))

ereid_useful

```


```{r}
shinobi_slang_terms <- shinobi_useful %>% select(word=slang_term)
ereid_slang_terms <- ereid_useful %>% select(word=slang)

lexicon_final <-lexicon_filtered_02 %>% 
    bind_rows(shinobi_slang_terms) %>%
    bind_rows(ereid_slang_terms)
lexicon_final %>% write_csv("../data/FOC_lexicon_003_final.csv")

lexicon_final%>% rmarkdown:::print.paged_df()
```


